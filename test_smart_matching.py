#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½åŒ¹é…åŠŸèƒ½æµ‹è¯•è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ™ºèƒ½åŒ¹é…å™¨å‡å°‘å¯¹ç¡¬ç¼–ç è§„åˆ™çš„ä¾èµ–
"""

from smart_matcher import create_smart_matcher
from rule_manager import get_rule_manager


def test_rule_manager():
    """æµ‹è¯•è§„åˆ™ç®¡ç†å™¨åŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯• 1: è§„åˆ™ç®¡ç†å™¨")
    print("=" * 60)
    
    rule_mgr = get_rule_manager()
    aliases, renames, gender_renames = rule_mgr.load_rules()
    
    print(f"âœ“ å·²åŠ è½½ {len(aliases)} æ¡åˆ«åè§„åˆ™")
    print(f"âœ“ å·²åŠ è½½ {len(renames)} æ¡é‡å‘½åè§„åˆ™")
    print(f"âœ“ å·²åŠ è½½ {len(gender_renames)} æ¡æ€§åˆ«è§„åˆ™")
    print(f"âœ“ è§„åˆ™ç‰ˆæœ¬: {rule_mgr.version}")
    
    # æ˜¾ç¤ºå‰5æ¡è§„åˆ™
    print("\nå‰5æ¡åˆ«åè§„åˆ™ç¤ºä¾‹:")
    for i, (alias, standard) in enumerate(aliases[:5], 1):
        print(f"  {i}. {alias:20s} -> {standard}")
    
    print()


def test_smart_matcher():
    """æµ‹è¯•æ™ºèƒ½åŒ¹é…å™¨åŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯• 2: æ™ºèƒ½åŒ¹é…å™¨")
    print("=" * 60)
    
    # åŠ è½½è§„åˆ™
    rule_mgr = get_rule_manager()
    aliases, _, _ = rule_mgr.load_rules()
    
    # åˆ›å»ºåŒ¹é…å™¨
    matcher = create_smart_matcher(aliases)
    
    # æ¨¡æ‹Ÿ Excel æ ‡å‡†é¡¹ç›®åˆ—è¡¨
    excel_items = [
        'é‡‡è¡€',
        'çœ¼ç§‘æ£€æŸ¥',
        'æ ‡å‡†æ—©é¤',
        'C13å‘¼æ°”è¯•éªŒ',
        'C14å‘¼æ°”è¯•éªŒ',
        'ä¹³è…ºå½©è‰²è¶…å£°',
        'å¥³æ€§å½©è‰²ç›†è…”è¶…å£°',
        'åäºŒå¯¼è”å¿ƒç”µå›¾',
        'è…¹éƒ¨å½©è‰²è¶…å£°',
        'è€³é¼»å’½å–‰æ£€æŸ¥',
        'ç”²çŠ¶è…ºå½©è‰²è¶…å£°',
        'èƒ¸éƒ¨CT',
        'è¡€æµå˜(æ–°)',
        'è‚åŠŸåä¸‰é¡¹',
        'ç©ºè…¹è¡€ç³–',
        'äººä½“æˆåˆ†åˆ†æ',
    ]
    
    # æ¨¡æ‹Ÿ OCR è¯†åˆ«ç»“æœï¼ˆåŒ…å«å„ç§å˜ä½“ï¼‰
    ocr_items = [
        # ç²¾ç¡®åŒ¹é…
        ('é‡‡è¡€', 'exact'),
        # è§„åˆ™åŒ¹é…
        ('é™è„‰é‡‡è¡€', 'alias'),
        ('çœ¼ç§‘å¸¸è§„', 'alias'),
        # æ¨¡ç³ŠåŒ¹é…
        ('ä¹³è…ºå½©è¶…', 'fuzzy'),
        ('å¿ƒç”µå›¾', 'fuzzy'),
        ('ç¢³13å‘¼æ°”', 'fuzzy'),
        # è¯­ä¹‰åŒ¹é…
        ('èƒ¸éƒ¨ CT', 'semantic'),
        ('è‚åŠŸèƒ½åä¸‰é¡¹', 'semantic'),
        ('ç”²çŠ¶è…ºè¶…å£°', 'semantic'),
        # éš¾ä»¥åŒ¹é…
        ('æœªçŸ¥é¡¹ç›®ABC', 'fail'),
    ]
    
    print("\nåŒ¹é…æµ‹è¯•ç»“æœ:")
    print(f"{'OCRè¯†åˆ«åç§°':<20s} {'åŒ¹é…ç»“æœ':<25s} {'é¢„æœŸç±»å‹':<10s} {'çŠ¶æ€'}")
    print("-" * 70)
    
    for ocr_item, expected_type in ocr_items:
        match = matcher.match(ocr_item, excel_items, threshold=75)
        if match:
            status = "âœ“"
            result = match
        else:
            status = "âœ—" if expected_type != 'fail' else "â—‹"
            result = "(æœªåŒ¹é…)"
        
        print(f"{ocr_item:<20s} {result:<25s} {expected_type:<10s} {status}")
    
    # æ˜¾ç¤ºåŒ¹é…ç»Ÿè®¡
    print("\nåŒ¹é…ç»Ÿè®¡:")
    stats = matcher.get_match_statistics()
    for method, count in stats.items():
        if count > 0:
            percentage = (count / stats['total'] * 100) if stats['total'] > 0 else 0
            print(f"  {method:12s}: {count:3d} æ¬¡ ({percentage:5.1f}%)")
    
    # å»ºè®®æ–°è§„åˆ™
    print("\nå»ºè®®æ·»åŠ çš„æ–°è§„åˆ™:")
    suggestions = matcher.suggest_new_rules(min_occurrences=1)
    if suggestions:
        for ocr, excel, count in suggestions[:5]:
            print(f"  [{count}æ¬¡] {ocr} -> {excel}")
    else:
        print("  (æš‚æ— å»ºè®®)")
    
    print()


def test_comparison():
    """å¯¹æ¯”æµ‹è¯•ï¼šæœ‰è§„åˆ™ vs æ— è§„åˆ™"""
    print("=" * 60)
    print("æµ‹è¯• 3: è§„åˆ™æ•°é‡å¯¹æ¯”")
    print("=" * 60)
    
    # åœºæ™¯1: ä½¿ç”¨å®Œæ•´è§„åˆ™åº“
    rule_mgr = get_rule_manager()
    aliases_full, _, _ = rule_mgr.load_rules()
    matcher_full = create_smart_matcher(aliases_full)
    
    # åœºæ™¯2: ä»…ä½¿ç”¨å°‘é‡æ ¸å¿ƒè§„åˆ™
    aliases_mini = [
        ['é™è„‰é‡‡è¡€', 'é‡‡è¡€'],
        ['çœ¼ç§‘å¸¸è§„', 'çœ¼ç§‘æ£€æŸ¥'],
        ['ä¹³è…ºå½©è¶…', 'ä¹³è…ºå½©è‰²è¶…å£°'],
    ]
    matcher_mini = create_smart_matcher(aliases_mini)
    
    # æµ‹è¯•æ•°æ®
    excel_items = [
        'é‡‡è¡€', 'çœ¼ç§‘æ£€æŸ¥', 'ä¹³è…ºå½©è‰²è¶…å£°', 'C13å‘¼æ°”è¯•éªŒ',
        'ç”²çŠ¶è…ºå½©è‰²è¶…å£°', 'åäºŒå¯¼è”å¿ƒç”µå›¾', 'ç©ºè…¹è¡€ç³–'
    ]
    
    ocr_items = [
        'é™è„‰é‡‡è¡€', 'çœ¼ç§‘å¸¸è§„', 'ä¹³è…ºå½©è¶…', 'ç¢³åä¸‰å‘¼æ°”æ£€æŸ¥',
        'ç”²çŠ¶è…ºå½©è¶…', 'å¸¸è§„å¿ƒç”µå›¾', 'ç©ºè…¹è¡€ç³–(GLU)'
    ]
    
    # æµ‹è¯•å®Œæ•´è§„åˆ™
    matched_full = sum(1 for item in ocr_items 
                      if matcher_full.match(item, excel_items, threshold=75))
    
    # æµ‹è¯•ç²¾ç®€è§„åˆ™
    matched_mini = sum(1 for item in ocr_items 
                      if matcher_mini.match(item, excel_items, threshold=75))
    
    print(f"\næµ‹è¯•é¡¹ç›®æ•°: {len(ocr_items)}")
    print(f"\næ–¹æ¡ˆ1 - å®Œæ•´è§„åˆ™åº“ ({len(aliases_full)} æ¡è§„åˆ™):")
    print(f"  åŒ¹é…æˆåŠŸ: {matched_full}/{len(ocr_items)} ({matched_full/len(ocr_items)*100:.1f}%)")
    
    print(f"\næ–¹æ¡ˆ2 - ç²¾ç®€è§„åˆ™åº“ ({len(aliases_mini)} æ¡è§„åˆ™) + æ™ºèƒ½åŒ¹é…:")
    print(f"  åŒ¹é…æˆåŠŸ: {matched_mini}/{len(ocr_items)} ({matched_mini/len(ocr_items)*100:.1f}%)")
    
    print(f"\nç»“è®º:")
    if matched_mini >= matched_full * 0.9:  # 90%ä»¥ä¸Šçš„æ•ˆæœ
        print(f"  âœ“ æ™ºèƒ½åŒ¹é…å¯ä»¥ç”¨ {len(aliases_mini)} æ¡è§„åˆ™è¾¾åˆ°æ¥è¿‘å®Œæ•´è§„åˆ™åº“çš„æ•ˆæœ")
        print(f"  âœ“ è§„åˆ™æ•°é‡å‡å°‘ {(1-len(aliases_mini)/len(aliases_full))*100:.0f}%")
    else:
        print(f"  â€¢ éœ€è¦æ›´å¤šè§„åˆ™æˆ–è°ƒæ•´åŒ¹é…é˜ˆå€¼")
    
    print()


def test_learning():
    """æµ‹è¯•å­¦ä¹ åŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯• 4: ç”¨æˆ·åé¦ˆå­¦ä¹ ")
    print("=" * 60)
    
    matcher = create_smart_matcher([])
    
    # æ¨¡æ‹Ÿç”¨æˆ·åé¦ˆçº æ­£
    feedbacks = [
        ('è‚åŠŸ', 'è‚åŠŸåä¸‰é¡¹'),
        ('è‚¾åŠŸ', 'è‚¾åŠŸèƒ½äº”é¡¹'),
        ('è¡€ç³–', 'ç©ºè…¹è¡€ç³–'),
    ]
    
    print("\nç”¨æˆ·åé¦ˆå­¦ä¹ è¿‡ç¨‹:")
    for ocr, correct in feedbacks:
        matcher.learn_from_feedback(ocr, correct)
        print(f"  âœ“ å­¦ä¹ : {ocr} -> {correct}")
    
    # æµ‹è¯•å­¦ä¹ æ•ˆæœ
    print("\nåº”ç”¨å­¦ä¹ ç»“æœ:")
    excel_items = ['è‚åŠŸåä¸‰é¡¹', 'è‚¾åŠŸèƒ½äº”é¡¹', 'ç©ºè…¹è¡€ç³–']
    
    for ocr in ['è‚åŠŸ', 'è‚¾åŠŸ', 'è¡€ç³–']:
        match = matcher.match(ocr, excel_items)
        print(f"  {ocr} -> {match if match else '(æœªåŒ¹é…)'}")
    
    # å¯¼å‡ºå­¦ä¹ è§„åˆ™
    learned = matcher.export_learned_rules()
    print(f"\nå¯å¯¼å‡º {len(learned)} æ¡å­¦ä¹ è§„åˆ™åˆ°æ­£å¼è§„åˆ™åº“")
    
    print()


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 60)
    print("æ™ºèƒ½åŒ¹é…ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60 + "\n")
    
    try:
        # æµ‹è¯•1: è§„åˆ™ç®¡ç†å™¨
        test_rule_manager()
        
        # æµ‹è¯•2: æ™ºèƒ½åŒ¹é…å™¨
        test_smart_matcher()
        
        # æµ‹è¯•3: è§„åˆ™æ•°é‡å¯¹æ¯”
        test_comparison()
        
        # æµ‹è¯•4: å­¦ä¹ åŠŸèƒ½
        test_learning()
        
        print("=" * 60)
        print("æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("=" * 60)
        
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("  1. ä¿ç•™æ ¸å¿ƒçš„ã€é«˜é¢‘çš„è§„åˆ™")
        print("  2. ä½¿ç”¨æ™ºèƒ½åŒ¹é…å¤„ç†ä½é¢‘å’Œå˜ä½“æƒ…å†µ")
        print("  3. å®šæœŸä»åŒ¹é…å†å²ä¸­æå–æ–°è§„åˆ™")
        print("  4. ç»“åˆç”¨æˆ·åé¦ˆæŒç»­ä¼˜åŒ–")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

